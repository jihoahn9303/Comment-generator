# Comment Generator with Gradio + FastAPI

**ìˆ˜ë§ì€ ì£¼ì„ì„ ì¼ì¼ì´ íƒ€ì´í•‘í•˜ê¸° ì‹«ì€ ë‹¹ì‹ ì„ ìœ„í•œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤ğŸ˜**

Gradio UIì— ì½”ë“œë¥¼ ì…ë ¥í•˜ë©´, ìë™ìœ¼ë¡œ ì£¼ì„ì„ ì¶”ê°€í•´ì£¼ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì œì‘í•˜ì˜€ìŠµë‹ˆë‹¤!!

í•„ìš”í•˜ë‹¤ë©´, ìƒì„±ëœ ì£¼ì„ì„ ì°¸ê³ í•˜ì—¬ ì—¬ëŸ¬ë¶„ì˜ ì…ë§›ì— ë§ê²Œ ë‚´ìš©ì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”ğŸ±â€ğŸ

ì£¼ì„ì˜ ë‚´ìš©ì´ 100% ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ëœ»í•œ ì‘ì›ì„ ë¶€íƒë“œë ¤ìš” :)



## Project process

![Comment_generator excalidraw](https://github.com/user-attachments/assets/4f1fc567-10cd-47d5-83ae-acb09106babf)

1. ê°œë°œ í™˜ê²½ì—ì„œ `Makefile`ì„ ì´ìš©í•˜ì—¬ `FastAPI` ê¸°ë°˜ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ `Docker image`ë¡œ `build`í•©ë‹ˆë‹¤.

2. `Makefile`ì— ëª…ì‹œëœ íŒŒì´í”„ë¼ì¸ì— ë”°ë¼, ë¹Œë“œê°€ ëë‚œ `Docker image`ëŠ” `GCP Artifact Registry`ì— ìë™ìœ¼ë¡œ ë°°í¬ë©ë‹ˆë‹¤.

3. `Makefile`ì— ëª…ì‹œëœ íŒŒì´í”„ë¼ì¸ì— ë”°ë¼, `GCP VM Instance`ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.

4. ìƒì„±ëœ `VM Instance`ëŠ” ìë™ìœ¼ë¡œ `GCP Artifact Registry`ì—ì„œ `Docker image`ë¥¼ ê°€ì ¸ì˜¤ê³ , ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤ > `FastAPI ì–´í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰`

5. ì´ì œ, ì—¬ëŸ¬ë¶„ë“¤ì€ `Gradio UI`ë¥¼ í†µí•´ ìë™ìœ¼ë¡œ ì½”ë“œ ì£¼ì„ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤ :)



## Usage

### ì„œë¹„ìŠ¤ URL

ë¸Œë¼ìš°ì €ë¥¼ í†µí•´, Gradio UIì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì£¼ì†ŒëŠ” ì•„ë˜ì™€ ê°™ì•„ìš”!

```
http://34.22.74.209:8000/gradio/
```

### Gradio UI

Gradio UIëŠ” ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì•„ìš”! 

![ì´ˆê¸°í™”ë©´](https://github.com/user-attachments/assets/fa4a7a55-aee3-4cb7-8619-060e6e92a46c)

í¬ê²Œ ë‹¤ìŒê³¼ ê°™ì€ ì»´í¬ë„ŒíŠ¸ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

```
1. ëª¨ë¸ ì¤€ë¹„ ìƒíƒœ í™•ì¸ -> ì½”ë“œ ì£¼ì„ ìƒì„±ì„ ìœ„í•´ í•„ìš”í•œ LLM ëª¨ë¸ì´ ì¤€ë¹„ëëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
2. íŒŒì´ì¬ ì½”ë“œ ì…ë ¥ íŒŒíŠ¸ -> ì›ë³¸ íŒŒì´ì¬ ì½”ë“œë¥¼ ì…ë ¥í•˜ëŠ” ê³³ì…ë‹ˆë‹¤.
3. ì£¼ì„ ë””ìŠ¤í”Œë ˆì´ -> LLM ëª¨ë¸ì— ì˜í•´ ì¶”ê°€ëœ ì£¼ì„ì„ ë³´ì—¬ì£¼ëŠ” ê³³ì…ë‹ˆë‹¤.
4. ëª¨ë¸ ì„ íƒ -> ì½”ë“œ ì£¼ì„ ìƒì„±ì— ì‚¬ìš©í•  LLM ëª¨ë¸ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```

ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì€ ê²½ìš°ì—ëŠ”, ì£¼ì„ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë•Œ, `ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°` ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ëª¨ë¸ì„ ë¡œë”©í•´ì£¼ì„¸ìš” (ì•½ 5~6ë¶„ ì†Œìš”)


### ë°ëª¨ ì˜ìƒ

https://github.com/user-attachments/assets/0a981032-3dfe-4558-9bc3-b0ef04ee054d


### ë°ëª¨ ê²°ê³¼ ì˜ˆì‹œ

[Before]

```
def stream_messages(
    model_endpoint_url: str,
    huggingface_token: str,
    tokenizer: Union[PreTrainedTokenizer, PreTrainedTokenizerFast], 
    python_code: str
):
    messages = generate_message(python_code)
    text = tokenizer.apply_chat_template(
        conversation=messages,
        tokenize=False,
        add_generation_prompt=True
    )
    
    inference_client= InferenceClient(model=model_endpoint_url, token=huggingface_token) 
    stream = inference_client.text_generation(
        prompt=text,
        stream=True,
        details=False,
        max_new_tokens=2048
    )
    
    result = ""
    for r in stream:
        result += r
        yield result
```


[After]

```
def stream_messages(
    model_endpoint_url: str,
    huggingface_token: str,
    tokenizer: Union[PreTrainedTokenizer, PreTrainedTokenizerFast], 
    python_code: str
):
    """
    Generate and stream messages using a Hugging Face model.

    This function takes a Python code string, generates messages based on it,
    tokenizes the messages, and then streams the generated text using a Hugging Face model.

    Args:
        model_endpoint_url (str): The URL of the Hugging Face model endpoint.
        huggingface_token (str): The token for authentication with the Hugging Face model.
        tokenizer (Union[PreTrainedTokenizer, PreTrainedTokenizerFast]): The tokenizer to be used for tokenizing the messages.
        python_code (str): The Python code string to be used as input for generating messages.

    Returns:
        Generator[str, None, None]: A generator that yields the streamed text generated by the Hugging Face model.
    """
    # Generate messages based on the Python code
    messages = generate_message(python_code)
    
    # Tokenize the messages
    text = tokenizer.apply_chat_template(
        conversation=messages,
        tokenize=False,
        add_generation_prompt=True
    )
    
    # Create an inference client for the Hugging Face model
    inference_client = InferenceClient(model=model_endpoint_url, token=huggingface_token) 
    
    # Stream the generated text using the Hugging Face model
    stream = inference_client.text_generation(
        prompt=text,
        stream=True,
        details=False,
        max_new_tokens=2048
    )
    
    # Initialize the result string
    result = ""
    
    # Yield the streamed text
    for r in stream:
        result += r
        yield result
```


### ì°¸ê³  ì‚¬í•­

1. ë¹„ìš© ì ˆê° ì°¨ì›ìœ¼ë¡œ, HuggingFaceì—ì„œ ì œê³µí•˜ëŠ” Dedicated endpoint ê¸°ëŠ¥ì„ í™œìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

2. í•´ë‹¹ Endpointë¥¼ í˜¸ì¶œí•  ì‹œ, ì§€ì •í•œ ì˜¤í”ˆ ì†ŒìŠ¤ LLM ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì£¼ì„ ìƒì„±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

3. ë§Œì•½, íŠ¹ì • ì‹œê°„(15ë¶„) ë™ì•ˆ Endpoint í˜¸ì¶œì´ ì—†ì„ ê²½ìš°, EndpointëŠ” ìë™ìœ¼ë¡œ ì¤‘ì§€ë©ë‹ˆë‹¤.

4. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë²„íŠ¼ì„ í†µí•´, Endpointë¥¼ ë‹¤ì‹œ í™œì„±í™”í•˜ëŠ” ê³¼ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

5. í•¨ìˆ˜ì— Type hintingì„ ì œê³µí•  ë•Œ, ë” ì •êµí•˜ê²Œ ì£¼ì„ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.



## Develop & Experiment environment

ê°œë°œ í™˜ê²½ì— ëŒ€í•œ ì£¼ìš” ì‚¬í•­ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

| Source                  | Version                                                                               |
| ----------------------- | ------------------------------------------------------------------------------------- |
| OS(Host)                | Host: Microsoft Windows 10 Pro build `19045` / NVIDIA GeForce RTX 3060 12GB           |
| Remote controller       | WSL2 / Ubuntu version: `20.04`                                                        |
| Python                  | `3.11.10`                                                                             |
| IDLE                    | Visual Studio code `1.75.1`                                                           |
| Docker                  | Docker desktop `4.26.1` / Engine version: `24.0.7`                                    |


## To-do list

1. Gradio ì»¤ìŠ¤í…€ UI ê°œì„  ì‘ì—…(ê°€ì‹œì„± ì¸¡ë©´)

2. ì‚¬ìš© ê°€ëŠ¥í•œ LLM ëª¨ë¸ ì¶”ê°€

3. í”„ë¡œì íŠ¸ ì½”ë“œ ì£¼ì„ ì¶”ê°€